{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T04:21:07.066860Z",
     "start_time": "2025-09-10T04:21:02.480234Z"
    }
   },
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "from langchain_openai import OpenAIEmbeddings,ChatOpenAI \n",
    "from ragas.embeddings import HuggingFaceEmbeddings\n",
    "from ragas.testset import TestsetGenerator\n",
    "from ragas.testset.synthesizers import SingleHopSpecificQuerySynthesizer, MultiHopSpecificQuerySynthesizer\n",
    "from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"sk-7695ab4ed4f249a4aa5a3f63dd8b1d1a\"\n",
    "os.environ['OPENAI_API_BASE'] = \"https://api.deepseek.com\"\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.embeddings.base import Embeddings as BaseEmbeddings\n",
    "from typing import List\n",
    "\n",
    "class SentenceTransformerEmbeddings(BaseEmbeddings):\n",
    "    def __init__(self, model_name: str = 'all-MiniLM-L6-v2'):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return self.model.encode(texts, convert_to_tensor=False).tolist()\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self.model.encode([text], convert_to_tensor=False).tolist()[0]\n",
    "\n",
    "# 使用示例\n",
    "texts = [\"This is a test sentence.\", \"This is another test sentence.\"]\n",
    "emb = HuggingFaceEmbeddings(model=\"BAAI/bge-m3\")\n",
    "generator_llm = ChatOpenAI(model = 'deepseek-chat')\n",
    "critic_llm = ChatOpenAI(model = 'deepseek-chat')\n",
    "# 修改生成器创建部分\n",
    "generator = TestsetGenerator(\n",
    "    llm=generator_llm,\n",
    "    embedding_model=emb\n",
    ")\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.schema import Document\n",
    "from pathlib import Path\n",
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "\n",
    "# 指定txt文件的路径\n",
    "file_path = 'data/HSR-JR615-2000_En.txt'\n",
    "\n",
    "# 使用TextLoader加载txt文件\n",
    "loader = TextLoader(file_path,encoding='utf-8')\n",
    "\n",
    "# 加载文档\n",
    "documents = loader.load()\n",
    "# 尝试不同的参数名称\n",
    "testset = generator.generate(\n",
    "    testset_size=10,  # 而非 test_size\n",
    "    num_personas=3,  # 可选，默认就是 3\n",
    "    batch_size=None,  # 可选，根据需要设定\n",
    "    callbacks=None,\n",
    "    token_usage_parser=None,\n",
    "    with_debugging_logs=False,\n",
    "    raise_exceptions=True,\n",
    "    return_executor=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_file = 'input.csv'\n",
    "output_file = 'output.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Q&A pairs Generating:   0%|          | 0/554 [00:33<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 137\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    136\u001b[0m prompt \u001b[38;5;241m=\u001b[39m _build_prompt(content, k_this)\n\u001b[1;32m--> 137\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mllm_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOutput only a JSON array, with each element containing user_input, reference_contexts, and reference.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# 解析\u001b[39;00m\n\u001b[0;32m    146\u001b[0m arr: List[Any] \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[1], line 61\u001b[0m, in \u001b[0;36mllm_chat\u001b[1;34m(messages, model, temperature, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m m \u001b[38;5;241m=\u001b[39m model \u001b[38;5;129;01mor\u001b[39;00m DEFAULT_MODEL\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 61\u001b[0m     resp \u001b[38;5;241m=\u001b[39m llm_completion(model\u001b[38;5;241m=\u001b[39mm, messages\u001b[38;5;241m=\u001b[39mmessages, api_base\u001b[38;5;241m=\u001b[39mBASE_URL, api_key\u001b[38;5;241m=\u001b[39mAPI_KEY, temperature\u001b[38;5;241m=\u001b[39mtemperature, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# 解析 OpenAI 风格返回\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\litellm\\utils.py:1218\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1216\u001b[0m         print_verbose(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[1;32m-> 1218\u001b[0m result \u001b[38;5;241m=\u001b[39m original_function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1219\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_streaming_request(\n\u001b[0;32m   1221\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   1222\u001b[0m     call_type\u001b[38;5;241m=\u001b[39mcall_type,\n\u001b[0;32m   1223\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\litellm\\main.py:1585\u001b[0m, in \u001b[0;36mcompletion\u001b[1;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, safety_identifier, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[0m\n\u001b[0;32m   1581\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m custom_llm_provider \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepseek\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1582\u001b[0m     \u001b[38;5;66;03m## COMPLETION CALL\u001b[39;00m\n\u001b[0;32m   1584\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1585\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mbase_llm_http_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1586\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1587\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1588\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1589\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1590\u001b[0m \u001b[43m            \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1591\u001b[0m \u001b[43m            \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1592\u001b[0m \u001b[43m            \u001b[49m\u001b[43macompletion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1593\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1594\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptional_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1595\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1596\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m   1597\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1598\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1599\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1600\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1601\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprovider_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprovider_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1602\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1603\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1604\u001b[0m         \u001b[38;5;66;03m## LOGGING - log the original exception returned\u001b[39;00m\n\u001b[0;32m   1605\u001b[0m         logging\u001b[38;5;241m.\u001b[39mpost_call(\n\u001b[0;32m   1606\u001b[0m             \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[0;32m   1607\u001b[0m             api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[0;32m   1608\u001b[0m             original_response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m   1609\u001b[0m             additional_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: headers},\n\u001b[0;32m   1610\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\litellm\\llms\\custom_httpx\\llm_http_handler.py:478\u001b[0m, in \u001b[0;36mBaseLLMHTTPHandler.completion\u001b[1;34m(self, model, messages, api_base, custom_llm_provider, model_response, encoding, logging_obj, optional_params, timeout, litellm_params, acompletion, stream, fake_stream, api_key, headers, client, provider_config)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    476\u001b[0m     sync_httpx_client \u001b[38;5;241m=\u001b[39m client\n\u001b[1;32m--> 478\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_common_sync_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43msync_httpx_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msync_httpx_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprovider_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprovider_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43msigned_json_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigned_json_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m provider_config\u001b[38;5;241m.\u001b[39mtransform_response(\n\u001b[0;32m    490\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    491\u001b[0m     raw_response\u001b[38;5;241m=\u001b[39mresponse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    500\u001b[0m     json_mode\u001b[38;5;241m=\u001b[39mjson_mode,\n\u001b[0;32m    501\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\litellm\\llms\\custom_httpx\\llm_http_handler.py:182\u001b[0m, in \u001b[0;36mBaseLLMHTTPHandler._make_common_sync_call\u001b[1;34m(self, sync_httpx_client, provider_config, api_base, headers, data, timeout, litellm_params, logging_obj, stream, signed_json_body)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mmax\u001b[39m(max_retry_on_unprocessable_entity_error, \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43msync_httpx_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m                \u001b[49m\u001b[43msigned_json_body\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msigned_json_body\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m    188\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    195\u001b[0m         hit_max_retry \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m max_retry_on_unprocessable_entity_error\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\litellm\\llms\\custom_httpx\\http_handler.py:763\u001b[0m, in \u001b[0;36mHTTPHandler.post\u001b[1;34m(self, url, data, json, params, headers, stream, timeout, files, content, logging_obj)\u001b[0m\n\u001b[0;32m    759\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    760\u001b[0m     req \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[0;32m    761\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, data\u001b[38;5;241m=\u001b[39mdata, json\u001b[38;5;241m=\u001b[39mjson, params\u001b[38;5;241m=\u001b[39mparams, headers\u001b[38;5;241m=\u001b[39mheaders, files\u001b[38;5;241m=\u001b[39mfiles, content\u001b[38;5;241m=\u001b[39mcontent  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    762\u001b[0m     )\n\u001b[1;32m--> 763\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    764\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32me:\\Python\\miniconda\\conda\\envs\\robot_qa_system\\lib\\site-packages\\httpx\\_client.py:928\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    927\u001b[0m     response\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 928\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32me:\\Python\\miniconda\\conda\\envs\\robot_qa_system\\lib\\site-packages\\httpx\\_client.py:922\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 922\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    924\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32me:\\Python\\miniconda\\conda\\envs\\robot_qa_system\\lib\\site-packages\\httpx\\_models.py:881\u001b[0m, in \u001b[0;36mResponse.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;124;03mRead and return the response content.\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_content\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 881\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content\n",
      "File \u001b[1;32me:\\Python\\miniconda\\conda\\envs\\robot_qa_system\\lib\\site-packages\\httpx\\_models.py:897\u001b[0m, in \u001b[0;36mResponse.iter_bytes\u001b[1;34m(self, chunk_size)\u001b[0m\n\u001b[0;32m    895\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[0;32m    896\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[1;32m--> 897\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m raw_bytes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_raw():\n\u001b[0;32m    898\u001b[0m         decoded \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(raw_bytes)\n\u001b[0;32m    899\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunker\u001b[38;5;241m.\u001b[39mdecode(decoded):\n",
      "File \u001b[1;32me:\\Python\\miniconda\\conda\\envs\\robot_qa_system\\lib\\site-packages\\httpx\\_models.py:951\u001b[0m, in \u001b[0;36mResponse.iter_raw\u001b[1;34m(self, chunk_size)\u001b[0m\n\u001b[0;32m    948\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[0;32m    950\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[1;32m--> 951\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m raw_stream_bytes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream:\n\u001b[0;32m    952\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_bytes_downloaded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(raw_stream_bytes)\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunker\u001b[38;5;241m.\u001b[39mdecode(raw_stream_bytes):\n",
      "File \u001b[1;32me:\\Python\\miniconda\\conda\\envs\\robot_qa_system\\lib\\site-packages\\httpx\\_client.py:153\u001b[0m, in \u001b[0;36mBoundSyncStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream:\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[1;32me:\\Python\\miniconda\\conda\\envs\\robot_qa_system\\lib\\site-packages\\httpx\\_transports\\default.py:127\u001b[0m, in \u001b[0;36mResponseStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_httpcore_stream:\n\u001b[0;32m    128\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m part\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\connection_pool.py:407\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\connection_pool.py:403\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream:\n\u001b[0;32m    404\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m part\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\http11.py:342\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 342\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\http11.py:334\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_body\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request, kwargs):\n\u001b[1;32m--> 334\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39m_receive_response_body(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    335\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\http11.py:203\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_body\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    200\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mData):\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Python\\miniconda\\conda\\envs\\robot_qa_system\\lib\\ssl.py:1292\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1290\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1291\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32me:\\Python\\miniconda\\conda\\envs\\robot_qa_system\\lib\\ssl.py:1165\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Any, List, Dict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 输入与输出\n",
    "chunks_csv = \"D:/MAKG_demo-master/MAKG_demo-master/RAG/data/semantic_chunks.filtered.csv\"\n",
    "kg_csv = \"D:/MAKG_demo-master/MAKG_demo-master/RAG/data/knowledge_graph.csv\"\n",
    "output_jsonl = \"D:/MAKG_demo-master/MAKG_demo-master/RAG/data/qa_pairs.jsonl\"\n",
    "\n",
    "# 读取分块与KG\n",
    "chunks_df = pd.read_csv(chunks_csv)\n",
    "kg_df = pd.read_csv(kg_csv)\n",
    "\n",
    "# 构建 chunk_id -> triples 列表映射\n",
    "chunk_to_triples: Dict[int, List[Dict[str, str]]] = {}\n",
    "for _, row in kg_df.iterrows():\n",
    "    cid = row.get(\"chunk_id\", None)\n",
    "    if pd.isna(cid):\n",
    "        continue\n",
    "    try:\n",
    "        cid_int = int(cid)\n",
    "    except Exception:\n",
    "        continue\n",
    "    triple = {\n",
    "        \"head\": str(row.get(\"node_1\", \"\")).strip(),\n",
    "        \"relation\": str(row.get(\"edge\", \"\")).strip(),\n",
    "        \"tail\": str(row.get(\"node_2\", \"\")).strip(),\n",
    "    }\n",
    "    if not triple[\"head\"] or not triple[\"relation\"] or not triple[\"tail\"]:\n",
    "        continue\n",
    "    chunk_to_triples.setdefault(cid_int, []).append(triple)\n",
    "\n",
    "# 取出文本与来源\n",
    "chunks = chunks_df[\"text\"].tolist()\n",
    "sources = chunks_df[\"source\"].tolist() if \"source\" in chunks_df.columns else [\"\"] * len(chunks)\n",
    "\n",
    "# 生成目标数量配置\n",
    "total_target = 3  # 目标总问答对数，可按需调整\n",
    "per_chunk = max(1, total_target // max(1, len(chunks)))\n",
    "remainder = total_target % max(1, len(chunks))\n",
    "\n",
    "# 简单选择顺序索引（可替换为抽样）\n",
    "indices = list(range(len(chunks)))\n",
    "\n",
    "\n",
    "# 一个最小的聊天调用封装，返回字符串\n",
    "from typing import Optional\n",
    "import os\n",
    "from litellm import completion as llm_completion\n",
    "\n",
    "DEFAULT_MODEL = \"deepseek-chat\"\n",
    "BASE_URL = \"https://api.deepseek.com/v1\"\n",
    "API_KEY = \"sk-88cea9654d1f43328b373fea4774a0e8\"\n",
    "\n",
    "def llm_chat(messages: List[Dict[str, str]], model: Optional[str] = None, temperature: float = 0.0, **kwargs) -> str:\n",
    "    m = model or DEFAULT_MODEL\n",
    "    try:\n",
    "        resp = llm_completion(model=m, messages=messages, api_base=BASE_URL, api_key=API_KEY, temperature=temperature, **kwargs)\n",
    "        # 解析 OpenAI 风格返回\n",
    "        content = None\n",
    "        if isinstance(resp, dict):\n",
    "            content = resp.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "        else:\n",
    "            choices = getattr(resp, \"choices\", [])\n",
    "            if choices:\n",
    "                msg = getattr(choices[0], \"message\", None)\n",
    "                if msg:\n",
    "                    try:\n",
    "                        content = msg.get(\"content\")\n",
    "                    except Exception:\n",
    "                        content = getattr(msg, \"content\", \"\")\n",
    "        return (content or \"\").strip()\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "# Prompt 生成\n",
    "\n",
    "def _build_prompt(content: str, k: int) -> str:\n",
    "    return (\n",
    "        \"You are an industrial document annotation assistant. Please generate high-quality English Q&A pairs based on the provided content.\\n\"\n",
    "        \"Strict Requirements:\\n\"\n",
    "        \"1. All questions and answers must be strictly based on the provided content, without introducing external knowledge;\\n\"\n",
    "        \"2. Each data item should be output as an object with fields: user_input (concise and natural English user question), reference_contexts (key sentences selected from the content), reference (detailed and content-rich English answer based on these contexts);\\n\"\n",
    "        \"3. The reference must be detailed, content-rich, and directly supported by reference_contexts;\\n\"\n",
    "        \"4. If the content is too brief, fragmented, or insufficient to form complete Q&A pairs (such as simple list items or phrases), do not generate any Q&A pairs;\\n\"\n",
    "        \"5. Avoid generating Q&A pairs from overly brief content (like simple entries such as '(5) Maintenance operations must be performed with power on...)';\\n\"\n",
    "        \"6. Output strictly as a JSON array, without any extra text or code blocks.\\n\\n\"\n",
    "        \"Quality Requirements:\\n\"\n",
    "        \"- user_input should be concise and natural, like questions real users would ask\\n\"\n",
    "        \"- reference should be content-rich and detailed, providing complete explanations\\n\"\n",
    "        \"- Only generate high-quality, substantive Q&A pairs\\n\\n\"\n",
    "        f\"Please generate 1 to {k} high-quality data items. If the content does not meet requirements, output an empty array [].\\n\\n\"\n",
    "        f\"Content:\\n{content}\\n\\n\"\n",
    "        \"Output only JSON array:\"\n",
    "    )\n",
    "\n",
    "# 主循环：根据分块内容生成问答对\n",
    "results: List[Dict[str, Any]] = []\n",
    "remaining = total_target\n",
    "triples_per_doc = 3\n",
    "\n",
    "for idx, i in enumerate(tqdm(indices, desc=\"Q&A pairs Generating\")):\n",
    "    if remaining <= 0:\n",
    "        break\n",
    "\n",
    "    txt = (chunks[i] or \"\").strip()\n",
    "    src = sources[i] if i < len(sources) else \"\"\n",
    "\n",
    "    # 拼接少量三元组，帮助关注关键信息\n",
    "    triples_txt = \"\"\n",
    "    tri_list = chunk_to_triples.get(i, [])\n",
    "    if tri_list:\n",
    "        lines: List[str] = []\n",
    "        for t in tri_list[: max(1, triples_per_doc)]:\n",
    "        # for t in tri_list:\n",
    "            h = str(t.get(\"head\", \"\")).strip()\n",
    "            r = str(t.get(\"relation\", \"\")).strip()\n",
    "            ta = str(t.get(\"tail\", \"\")).strip()\n",
    "            if h and r and ta:\n",
    "                lines.append(f\"- ({h}) --{r}--> ({ta})\")\n",
    "        if lines:\n",
    "            triples_txt = \"\\n\\nKey Triples:\\n\" + \"\\n\".join(lines)\n",
    "\n",
    "    # content = txt + triples_txt\n",
    "    content = txt\n",
    "\n",
    "    # 分配数量\n",
    "    k_this = per_chunk + (1 if idx < remainder else 0)\n",
    "    k_this = min(k_this, remaining)\n",
    "    if k_this <= 0:\n",
    "        continue\n",
    "\n",
    "    prompt = _build_prompt(content, k_this)\n",
    "    resp = llm_chat(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Output only a JSON array, with each element containing user_input, reference_contexts, and reference.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "    # 解析\n",
    "    arr: List[Any] = []\n",
    "    try:\n",
    "        m = re.search(r\"\\[.*\\]\", resp, flags=re.S)\n",
    "        arr = json.loads(m.group(0) if m else resp)\n",
    "    except Exception:\n",
    "        arr = []\n",
    "\n",
    "    # 清洗并收集\n",
    "    for obj in arr:\n",
    "        if remaining <= 0:\n",
    "            break\n",
    "        if not isinstance(obj, dict):\n",
    "            continue\n",
    "        q = str(obj.get(\"user_input\", \"\")).strip()\n",
    "        rc = obj.get(\"reference_contexts\", [])\n",
    "        if isinstance(rc, str):\n",
    "            rc = [rc]\n",
    "        if not isinstance(rc, list):\n",
    "            rc = []\n",
    "        rc_clean = []\n",
    "        for x in rc:\n",
    "            sx = str(x).strip()\n",
    "            if sx:\n",
    "                rc_clean.append(sx)\n",
    "        rc_clean = rc_clean[:3]\n",
    "        ans = str(obj.get(\"reference\", \"\")).strip()\n",
    "        if not q or not ans or not rc_clean:\n",
    "            continue\n",
    "        results.append({\n",
    "            \"user_input\": q,\n",
    "            \"reference_contexts\": rc_clean,\n",
    "            \"reference\": ans,\n",
    "            \"source\": src,\n",
    "            \"chunk_id\": i,\n",
    "        })\n",
    "        remaining -= 1\n",
    "\n",
    "# 保存到 JSONL\n",
    "outp = Path(output_jsonl)\n",
    "outp.parent.mkdir(parents=True, exist_ok=True)\n",
    "with outp.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for item in results:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print({\"ok\": True, \"count\": len(results), \"out_path\": str(outp)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 覆盖/强化版 llm_chat：修复 litellm 需要明确 model 的问题\n",
    "from typing import Optional, List, Dict\n",
    "import os\n",
    "from litellm import completion as llm_completion\n",
    "\n",
    "# 健壮的默认值（环境变量若为空字符串则回退）\n",
    "DEFAULT_MODEL = (os.environ.get(\"LITELLM_MODEL\") or os.environ.get(\"OPENAI_MODEL\") or \"deepseek-chat\")\n",
    "BASE_URL = (os.environ.get(\"OPENAI_API_BASE\") or \"https://api.deepseek.com\")\n",
    "API_KEY = (os.environ.get(\"OPENAI_API_KEY\") or \"\")\n",
    "\n",
    "\n",
    "def llm_chat(messages: List[Dict[str, str]], model: Optional[str] = None, temperature: float = 0.0, **kwargs) -> str:\n",
    "    \"\"\"使用 litellm 调用，messages 采用 OpenAI 风格字典列表。\n",
    "    可通过传入 model 覆盖，或设置环境变量 LITELLM_MODEL/OPENAI_MODEL。\n",
    "    \"\"\"\n",
    "    m = (model or DEFAULT_MODEL)\n",
    "    if not m:\n",
    "        raise ValueError(\"litellm: 缺少模型名，请设置环境变量 LITELLM_MODEL 或传入 model 参数\")\n",
    "    try:\n",
    "        resp = llm_completion(\n",
    "            model=m,\n",
    "            messages=messages,\n",
    "            api_base=BASE_URL,\n",
    "            api_key=API_KEY,\n",
    "            temperature=temperature,\n",
    "            **kwargs,\n",
    "        )\n",
    "        # 解析 OpenAI 风格返回\n",
    "        content = None\n",
    "        if isinstance(resp, dict):\n",
    "            content = resp.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "        else:\n",
    "            choices = getattr(resp, \"choices\", [])\n",
    "            if choices:\n",
    "                msg = getattr(choices[0], \"message\", None)\n",
    "                if msg:\n",
    "                    try:\n",
    "                        content = msg.get(\"content\")\n",
    "                    except Exception:\n",
    "                        content = getattr(msg, \"content\", \"\")\n",
    "        return (content or \"\").strip()\n",
    "    except Exception as e:\n",
    "        # 返回空字符串避免中断主流程，也可改为 raise e 直接抛出\n",
    "        return \"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robot_qa_system",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
